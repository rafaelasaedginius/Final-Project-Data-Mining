{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff27733",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40ec56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n",
      "VRAM: 11.94 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CPU mode - training will be slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1052e92",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19d71c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Shape: (69865, 29)\n",
      "First few texts:\n",
      "0                                            game hurt\n",
      "1    sexuality ‚Äô grouping category make different o...\n",
      "2                              right dont care fuck em\n",
      "3                                      man love reddit\n",
      "4                             name nowhere near falcon\n",
      "Name: text, dtype: object\n",
      "\n",
      "Number of emotion labels: 28\n",
      "Emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "Features shape: (69865,)\n",
      "Labels shape: (69865, 28)\n",
      "Sample text: game hurt...\n",
      "Sample labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Emotions for first sample: ['sadness']\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_csv('dataset_preprocessed.csv')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"First few texts:\\n{df['text'].head()}\\n\")\n",
    "\n",
    "# Define emotion columns\n",
    "emotion_cols = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', \n",
    "                'caring', 'confusion', 'curiosity', 'desire', 'disappointment', \n",
    "                'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', \n",
    "                'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', \n",
    "                'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', \n",
    "                'neutral']\n",
    "\n",
    "print(f\"Number of emotion labels: {len(emotion_cols)}\")\n",
    "print(f\"Emotions: {emotion_cols}\\n\")\n",
    "\n",
    "# Get labels\n",
    "X = df['text'].values\n",
    "y = df[emotion_cols].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Sample text: {X[0][:100]}...\")\n",
    "print(f\"Sample labels: {y[0]}\")\n",
    "print(f\"Emotions for first sample: {[emotion_cols[i] for i in range(len(emotion_cols)) if y[0][i] == 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb6b48",
   "metadata": {},
   "source": [
    "## 3. Tokenize and Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32392b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: bert-base-uncased\n",
      "Tokenizer vocabulary size: 30522\n",
      "Tokenizing 69865 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69865/69865 [00:03<00:00, 17933.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input IDs shape: (69865, 256)\n",
      "Attention masks shape: (69865, 256)\n",
      "Sample input IDs (first 20 tokens): [ 101 2208 3480  102    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "Sample attention mask (first 20 tokens): [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "# Tokenize texts\n",
    "def tokenize_texts(texts, max_length=256, batch_size=32):\n",
    "    \"\"\"Tokenize texts with BERT tokenizer\"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    print(f\"Tokenizing {len(texts)} texts...\")\n",
    "    for text in tqdm(texts):\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "    \n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "# Tokenize all texts\n",
    "input_ids, attention_masks = tokenize_texts(X, max_length=256)\n",
    "\n",
    "print(f\"\\nInput IDs shape: {input_ids.shape}\")\n",
    "print(f\"Attention masks shape: {attention_masks.shape}\")\n",
    "print(f\"Sample input IDs (first 20 tokens): {input_ids[0][:20]}\")\n",
    "print(f\"Sample attention mask (first 20 tokens): {attention_masks[0][:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c641f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 55892\n",
      "Validation set size: 6986\n",
      "Test set size: 6987\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 1747\n",
      "Validation batches: 219\n",
      "Test batches: 219\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X_train_ids, X_temp_ids, X_train_mask, X_temp_mask, y_train, y_temp = train_test_split(\n",
    "    input_ids, attention_masks, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_val_ids, X_test_ids, X_val_mask, X_test_mask, y_val, y_test = train_test_split(\n",
    "    X_temp_ids, X_temp_mask, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(X_train_ids)}\")\n",
    "print(f\"Validation set size: {len(X_val_ids)}\")\n",
    "print(f\"Test set size: {len(X_test_ids)}\")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_ids = torch.tensor(X_val_ids, dtype=torch.long)\n",
    "X_val_mask = torch.tensor(X_val_mask, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_ids, X_val_mask, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5663e6",
   "metadata": {},
   "source": [
    "## 4. Define BERT Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752a8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a28b712bfcb4ef99068c4c658140258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized:\n",
      "Number of labels: 28\n",
      "Model architecture:\n",
      "BertMultiLabelClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=28, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss_fn): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BertMultiLabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT-based Multi-Label Emotion Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3):\n",
    "        super(BertMultiLabelClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained BERT model\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.config = self.bert.config\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Classification head\n",
    "        hidden_size = self.config.hidden_size\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_labels)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Loss function for multi-label classification\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT outputs\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token representation (first token)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.dropout(cls_output)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Apply sigmoid for multi-label classification\n",
    "        logits = self.sigmoid(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def compute_loss(self, logits, labels):\n",
    "        return self.loss_fn(logits, labels)\n",
    "\n",
    "# Initialize model\n",
    "num_labels = len(emotion_cols)\n",
    "model = BertMultiLabelClassifier(model_name, num_labels, dropout_rate=0.3)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model initialized:\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(f\"Model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e8d6d",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb01438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (input_ids, attention_mask, labels) in enumerate(tqdm(train_loader)):\n",
    "        # Move to device\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = model.compute_loss(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def validate(model, val_loader, device, threshold=0.5):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in tqdm(val_loader):\n",
    "            # Move to device\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = model.compute_loss(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            preds = (logits > threshold).cpu().numpy()\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels_np)\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hamming = hamming_loss(all_labels, all_preds)\n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return avg_loss, hamming, f1_micro, f1_macro, all_preds, all_labels\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad10e5",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3e751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training (optimized: 3 epochs, batch_size=16)...\n",
      "\n",
      "Epoch 1/3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3494 [01:05<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, optimizer, scheduler, device)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss = model.compute_loss(logits, labels)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mBertMultiLabelClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m     35\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(cls_output)\n\u001b[32m     36\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc1(x)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     39\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:133\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\M S I\\Documents\\ITS\\Semester 5\\Data Mining\\Final-Project-Data-Mining\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1704\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1702\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "num_epochs = 3  # Reduced from 5 to 3 epochs\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Use smaller batch size for faster iterations (but may need more memory)\n",
    "batch_size_training = 16  # Reduced from 32\n",
    "\n",
    "# Recreate train loader with smaller batch size\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_training, shuffle=True)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(total_steps * 0.1),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_hamming': [],\n",
    "    'val_f1_micro': [],\n",
    "    'val_f1_macro': []\n",
    "}\n",
    "\n",
    "best_val_f1 = 0\n",
    "patience = 2  # Reduced from 3 to 2 (stop earlier if no improvement)\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop\n",
    "print(f\"Starting training (optimized: 3 epochs, batch_size={batch_size_training})...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, hamming, f1_micro, f1_macro, _, _ = validate(model, val_loader, device)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_hamming'].append(hamming)\n",
    "    history['val_f1_micro'].append(f1_micro)\n",
    "    history['val_f1_macro'].append(f1_macro)\n",
    "    \n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Hamming Loss: {hamming:.4f}\")\n",
    "    print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if f1_macro > best_val_f1:\n",
    "        best_val_f1 = f1_macro\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_emotion_classifier.pt')\n",
    "        print(\"‚úì Model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_emotion_classifier.pt'))\n",
    "print(\"Best model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279aaae",
   "metadata": {},
   "source": [
    "## 7. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26862827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Hamming Loss\n",
    "axes[0, 1].plot(history['val_hamming'], label='Hamming Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Hamming Loss')\n",
    "axes[0, 1].set_title('Validation Hamming Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# F1 Micro\n",
    "axes[1, 0].plot(history['val_f1_micro'], label='F1 Micro')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].set_title('Validation F1 Score (Micro)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# F1 Macro\n",
    "axes[1, 1].plot(history['val_f1_macro'], label='F1 Macro')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('Validation F1 Score (Macro)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e5e1bc",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae29558",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\\n\")\n",
    "test_loss, test_hamming, test_f1_micro, test_f1_macro, test_preds, test_labels = validate(model, test_loader, device)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Hamming Loss: {test_hamming:.4f}\")\n",
    "print(f\"F1 Score (Micro): {test_f1_micro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {test_f1_macro:.4f}\")\n",
    "print()\n",
    "\n",
    "# Per-emotion metrics\n",
    "print(\"Per-Emotion F1 Scores:\")\n",
    "print(\"-\" * 60)\n",
    "report = classification_report(test_labels, test_preds, target_names=emotion_cols, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c859a9",
   "metadata": {},
   "source": [
    "## 9. Inference - Predict Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions(text, model, tokenizer, device, emotion_cols, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict emotions for a given text\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = logits.cpu().numpy()[0]\n",
    "    \n",
    "    # Get predicted emotions\n",
    "    predicted_emotions = []\n",
    "    emotion_probs = {}\n",
    "    \n",
    "    for emotion, prob in zip(emotion_cols, probs):\n",
    "        emotion_probs[emotion] = float(prob)\n",
    "        if prob > threshold:\n",
    "            predicted_emotions.append((emotion, prob))\n",
    "    \n",
    "    # Sort by probability\n",
    "    predicted_emotions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return predicted_emotions, emotion_probs\n",
    "\n",
    "# Test with sample texts\n",
    "print(\"=\" * 80)\n",
    "print(\"EMOTION PREDICTION ON SAMPLE TEXTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample_texts = [\n",
    "    \"I'm so happy and excited about this amazing news!\",\n",
    "    \"This is absolutely terrible and I hate it.\",\n",
    "    \"I don't understand what's happening here.\",\n",
    "    \"Thank you so much for your help and support!\",\n",
    "    \"I'm really worried and anxious about the situation.\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"\\n{i}. Text: {text}\")\n",
    "    predicted, probs = predict_emotions(text, model, tokenizer, device, emotion_cols, threshold=0.5)\n",
    "    \n",
    "    print(f\"   Predicted emotions (threshold=0.5):\")\n",
    "    if predicted:\n",
    "        for emotion, prob in predicted:\n",
    "            print(f\"   - {emotion:15s}: {prob:.4f}\")\n",
    "    else:\n",
    "        print(f\"   - No emotions detected with threshold=0.5\")\n",
    "    \n",
    "    print(f\"\\n   Top 5 emotions by probability:\")\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for emotion, prob in sorted_probs:\n",
    "        print(f\"   - {emotion:15s}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c27352",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97637d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each emotion\n",
    "emotion_metrics = {}\n",
    "for i, emotion in enumerate(emotion_cols):\n",
    "    cm = confusion_matrix(test_labels[:, i], test_preds[:, i], labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    emotion_metrics[emotion] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'support': (tp + fn)\n",
    "    }\n",
    "\n",
    "# Create summary dataframe\n",
    "metrics_df = pd.DataFrame(emotion_metrics).T\n",
    "metrics_df = metrics_df.sort_values('f1', ascending=False)\n",
    "\n",
    "print(\"\\nPer-Emotion Performance Summary:\")\n",
    "print(metrics_df.to_string())\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top emotions by F1 score\n",
    "top_emotions = metrics_df.head(10)\n",
    "axes[0].barh(range(len(top_emotions)), top_emotions['f1'])\n",
    "axes[0].set_yticks(range(len(top_emotions)))\n",
    "axes[0].set_yticklabels(top_emotions.index)\n",
    "axes[0].set_xlabel('F1 Score')\n",
    "axes[0].set_title('Top 10 Emotions by F1 Score')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Emotion support distribution\n",
    "emotion_support = metrics_df['support'].astype(int).sort_values(ascending=False).head(10)\n",
    "axes[1].bar(range(len(emotion_support)), emotion_support.values)\n",
    "axes[1].set_xticks(range(len(emotion_support)))\n",
    "axes[1].set_xticklabels(emotion_support.index, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Number of Samples')\n",
    "axes[1].set_title('Top 10 Emotions by Support')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEmotion performance plot saved as 'emotion_performance.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4049e1d",
   "metadata": {},
   "source": [
    "## 11. Save Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "print(\"Saving model...\")\n",
    "torch.save(model.state_dict(), 'emotion_classifier_finetuned.pt')\n",
    "\n",
    "# Save model configuration\n",
    "config = {\n",
    "    'model_name': model_name,\n",
    "    'num_labels': num_labels,\n",
    "    'emotion_cols': emotion_cols,\n",
    "    'max_length': 256,\n",
    "    'dropout_rate': 0.3\n",
    "}\n",
    "\n",
    "with open('model_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "# Save metrics\n",
    "metrics_summary = {\n",
    "    'test_loss': float(test_loss),\n",
    "    'test_hamming_loss': float(test_hamming),\n",
    "    'test_f1_micro': float(test_f1_micro),\n",
    "    'test_f1_macro': float(test_f1_macro),\n",
    "    'training_config': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'weight_decay': weight_decay\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=4)\n",
    "\n",
    "print(\"‚úì Model saved as 'emotion_classifier_finetuned.pt'\")\n",
    "print(\"‚úì Configuration saved as 'model_config.json'\")\n",
    "print(\"‚úì Metrics saved as 'model_metrics.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85d4b7",
   "metadata": {},
   "source": [
    "## 12. Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EMOTION CLASSIFICATION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä DATASET INFORMATION:\")\n",
    "print(f\"  ‚Ä¢ Total samples: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Number of emotions: {len(emotion_cols)}\")\n",
    "print(f\"  ‚Ä¢ Train/Val/Test split: {len(X_train_ids)}/{len(X_val_ids)}/{len(X_test_ids)}\")\n",
    "print(f\"  ‚Ä¢ Multi-label: Yes (average {y.sum(axis=1).mean():.2f} emotions per text)\")\n",
    "\n",
    "print(\"\\nü§ñ MODEL INFORMATION:\")\n",
    "print(f\"  ‚Ä¢ Architecture: BERT Fine-Tuning (transformer-based)\")\n",
    "print(f\"  ‚Ä¢ Base model: {model_name}\")\n",
    "print(f\"  ‚Ä¢ Max sequence length: 256 tokens\")\n",
    "print(f\"  ‚Ä¢ Classification layers: 768 ‚Üí 256 ‚Üí {num_labels} (BCELoss)\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è TRAINING CONFIGURATION:\")\n",
    "print(f\"  ‚Ä¢ Epochs: {num_epochs}\")\n",
    "print(f\"  ‚Ä¢ Batch size: {batch_size}\")\n",
    "print(f\"  ‚Ä¢ Learning rate: {learning_rate}\")\n",
    "print(f\"  ‚Ä¢ Optimizer: AdamW with linear warmup scheduler\")\n",
    "print(f\"  ‚Ä¢ Early stopping: Yes (patience={patience})\")\n",
    "\n",
    "print(\"\\nüìà TEST SET PERFORMANCE:\")\n",
    "print(f\"  ‚Ä¢ Loss: {test_loss:.4f}\")\n",
    "print(f\"  ‚Ä¢ Hamming Loss: {test_hamming:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score (Micro): {test_f1_micro:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score (Macro): {test_f1_macro:.4f}\")\n",
    "\n",
    "print(\"\\nüéØ TOP 5 BEST PERFORMING EMOTIONS:\")\n",
    "for i, (emotion, metrics) in enumerate(metrics_df.head(5).iterrows(), 1):\n",
    "    print(f\"  {i}. {emotion:15s} - F1: {metrics['f1']:.4f}, Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "print(\"\\nüíæ SAVED FILES:\")\n",
    "print(f\"  ‚Ä¢ best_emotion_classifier.pt - Best model checkpoint\")\n",
    "print(f\"  ‚Ä¢ emotion_classifier_finetuned.pt - Final fine-tuned model\")\n",
    "print(f\"  ‚Ä¢ model_config.json - Model configuration\")\n",
    "print(f\"  ‚Ä¢ model_metrics.json - Test metrics\")\n",
    "print(f\"  ‚Ä¢ training_history.png - Training history plots\")\n",
    "print(f\"  ‚Ä¢ emotion_performance.png - Emotion performance analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
